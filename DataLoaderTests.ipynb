{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6c1dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import shutil\n",
    "\n",
    "import pydicom as dicom\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad16fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/schama/Downloads/rsna-breast-cancer-detection/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d2a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DICOMDataset(Dataset):\n",
    "    def __init__(self, dicom_dir, csv_file, transform=None):\n",
    "        self.dicom_dir = dicom_dir\n",
    "        self.labels = pd.read_csv(csv_file)\n",
    "        self.imgs_names = os.listdir(dicom_dir)\n",
    "        #self.imgs_len = len(self.imgs_names)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load DICOM image\n",
    "        file_name = self.labels.iloc[idx, 0]\n",
    "        file_path = os.path.join(self.dicom_dir, file_name)\n",
    "        image_data = dicom.dcmread(file_path).pixel_array\n",
    "        \n",
    "        #image_data = np.expand_dims(image_data, axis=0)\n",
    "        image = torch.from_numpy(image_data).float64()\n",
    "        \n",
    "        # Load metadata\n",
    "        label = self.labels.iloc[idx, 1]\n",
    "        #metadata_tensor = torch.tensor([label], dtype=torch.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            seg = self.transform(seg)\n",
    "        \n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da718369",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DICOMDataset('./train_test', './labels_test2.csv')\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df30b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    x, y = batch\n",
    "    plot_batch(x, y)\n",
    "    print('Batch size:', x.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adcbac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = itk.imread(path+'train_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d2f9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imge_np = itk.array_view_from_image(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4932bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = dicom.dcmread(path+'train_images/249677.dcm').pixel_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc97695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dicom.read_file(path+'train_images/249677.dcm').pixel_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81afc5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1cecd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 3328)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "352dbb46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb63f21d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.uint16. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.uint16. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1baf1fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.reshape(image_data, (image_data.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301dfd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DICOM to JPG/PNG via openCV\n",
    "def convert_images(filename, img_type='jpg'):\n",
    "    \"\"\"Reads a dcm file and saves the files as png/jpg\n",
    "    \n",
    "    Args:\n",
    "        filename: path to the dcm file\n",
    "        img_type: format of the processed file (jpg or png)\n",
    "        \n",
    "    \"\"\"\n",
    "    # extract the name of the file\n",
    "    name = filename.parts[-1]\n",
    "    \n",
    "    # read the dcm file\n",
    "    ds = pydicom.read_file(str(filename)) \n",
    "    img = ds.pixel_array\n",
    "    \n",
    "    # save the image as jpg/png\n",
    "    if img_type==\"jpg\":\n",
    "        cv2.imwrite(outdir + name.replace('.dcm','.jpg'), img)\n",
    "    else:\n",
    "        cv2.imwrite(outdir + name.replace('.dcm','.png'), img)\n",
    "\n",
    "# Using dask \n",
    "all_images = [dd.delayed(convert_images)(all_files[x]) for x in range(len(all_files))]\n",
    "dd.compute(all_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECGJupyter",
   "language": "python",
   "name": "ecgjupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
